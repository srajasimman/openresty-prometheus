tcp_nodelay on;

lua_shared_dict prometheus_metrics 10M;

error_log stderr;

map $upstream_cache_status $cache_status {
    default  $upstream_cache_status;
    ''       "NONE";
}

init_worker_by_lua_block {
    prometheus = require("prometheus").init("prometheus_metrics",{sync_interval=0.4})
    metric_requests = prometheus:counter("nginx_http_requests_total","Number of HTTP requests", {"host", "status", "request_method", "cache_status"})
    metric_latency = prometheus:histogram("nginx_http_request_duration_seconds","HTTP request latency", {"host"})
    metric_connections = prometheus:gauge("nginx_http_connections","Number of HTTP connections", {"state"})
}
log_by_lua_block {
    local excluded_uris = "^/(health|metrics|stub_status)$"
    if not ngx.re.match(ngx.var.request_uri, excluded_uris) then
        metric_requests:inc(1, {ngx.var.server_name, ngx.var.status, ngx.var.request_method, ngx.var.cache_status})
        metric_latency:observe(tonumber(ngx.var.request_time),{ngx.var.server_name})
    end
}
header_filter_by_lua_block {
    ngx.header["server"] = nil
}

server {
    listen 8080;

    access_log off;

    # Allow all RFC 1918 address blocks
    allow 10.0.0.0/8;
    allow 172.16.0.0/12;
    allow 192.168.0.0/16;
    deny all;

    location /stub_status {
        stub_status;
    }
}

server {
    listen 9145;

    access_log off;

    # Allow all RFC 1918 address blocks
    allow 10.0.0.0/8;
    allow 172.16.0.0/12;
    allow 192.168.0.0/16;
    deny all;

    location /metrics {
        content_by_lua_block {
            metric_connections:set(ngx.var.connections_active, {"active"})
            metric_connections:set(ngx.var.connections_reading, {"reading"})
            metric_connections:set(ngx.var.connections_waiting, {"waiting"})
            metric_connections:set(ngx.var.connections_writing, {"writing"})
            prometheus:collect()
        }
    }
}
